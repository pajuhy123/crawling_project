{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parser.py\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"mydjango.settings.prod_aws_eb\")\n",
    "import django\n",
    "django.setup()\n",
    "\n",
    "###########\n",
    "from blog.models import CrawlingData\n",
    "###########\n",
    "#data = requests.get(\"url\")  \n",
    "#print(data.encoding) // 키 값 알아내는 법,,//키==싸이트의 인코딩 방식\n",
    "encoding_map = {'437': 'cp437',\n",
    " '646': 'ascii',\n",
    " '850': 'cp850',\n",
    " '852': 'cp852',\n",
    " '855': 'cp855',\n",
    " '857': 'cp857',\n",
    " '860': 'cp860',\n",
    " '861': 'cp861',\n",
    " '862': 'cp862',\n",
    " '863': 'cp863',\n",
    " '865': 'cp865',\n",
    " '866': 'cp866',\n",
    " '869': 'cp869',\n",
    " '8859': 'latin_1',\n",
    " '932': 'cp932',\n",
    " '936': 'gbk',\n",
    " '949': 'cp949',\n",
    " '950': 'cp950',\n",
    " 'CP-GR': 'cp869',\n",
    " 'CP-IS': 'cp861',\n",
    " 'EBCDIC-CP-BE': 'cp500',\n",
    " 'EBCDIC-CP-CH': 'cp500',\n",
    " 'EBCDIC-CP-HE': 'cp424',\n",
    " 'IBM037': 'cp037',\n",
    " 'IBM039': 'cp037',\n",
    " 'IBM424': 'cp424',\n",
    " 'IBM437': 'cp437',\n",
    " 'IBM500': 'cp500',\n",
    " 'IBM775': 'cp775',\n",
    " 'IBM850': 'cp850',\n",
    " 'IBM852': 'cp852',\n",
    " 'IBM855': 'cp855',\n",
    " 'IBM857': 'cp857',\n",
    " 'IBM860': 'cp860',\n",
    " 'IBM861': 'cp861',\n",
    " 'IBM862': 'cp862',\n",
    " 'IBM863': 'cp863',\n",
    " 'IBM864': 'cp864',\n",
    " 'IBM865': 'cp865',\n",
    " 'IBM866': 'cp866',\n",
    " 'IBM869': 'cp869',\n",
    " 'L1': 'latin_1',\n",
    " 'L2': 'iso8859_2',\n",
    " 'L3': 'iso8859_3',\n",
    " 'L4': 'iso8859_4',\n",
    " 'L5': 'iso8859_9',\n",
    " 'L6': 'iso8859_10',\n",
    " 'L8': 'iso8859_14',\n",
    " 'U16': 'utf_16',\n",
    " 'U7': 'utf_7',\n",
    " 'U8': 'utf_8',\n",
    " 'UTF': 'utf_8',\n",
    " 'UTF-16BE': 'utf_16_be',\n",
    " 'UTF-16LE': 'utf_16_le',\n",
    " 'arabic': 'iso8859_6',\n",
    " 'big5-hkscs': 'big5hkscs',\n",
    " 'big5-tw': 'big5',\n",
    " 'chinese': 'gb2312',\n",
    " 'cp1361': 'johab',\n",
    " 'cp154': 'ptcp154',\n",
    " 'cp819': 'latin_1',\n",
    " 'cp936': 'gbk',\n",
    " 'csbig5': 'big5',\n",
    " 'csiso2022jp': 'iso2022_jp',\n",
    " 'csiso2022kr': 'iso2022_kr',\n",
    " 'csiso58gb231280': 'gb2312',\n",
    " 'csptcp154': 'ptcp154',\n",
    " 'csshiftjis': 'shift_jis',\n",
    " 'cyrillic': 'iso8859_5',\n",
    " 'cyrillic-asian': 'ptcp154',\n",
    " 'euc-cn': 'gb2312',\n",
    " 'euccn': 'gb2312',\n",
    " 'eucgb2312-cn': 'gb2312',\n",
    " 'eucjis2004': 'euc_jis_2004',\n",
    " 'eucjisx0213': 'euc_jisx0213',\n",
    " 'eucjp': 'euc_jp',\n",
    " 'euckr': 'euc_kr',\n",
    " 'gb18030-2000': 'gb18030',\n",
    " 'gb2312-1980': 'gb2312',\n",
    " 'gb2312-80': 'gb2312',\n",
    " 'greek': 'iso8859_7',\n",
    " 'greek8': 'iso8859_7',\n",
    " 'hebrew': 'iso8859_8',\n",
    " 'hkscs': 'big5hkscs',\n",
    " 'hz-gb': 'hz',\n",
    " 'hz-gb-2312': 'hz',\n",
    " 'hzgb': 'hz',\n",
    " 'ibm1026': 'cp1026',\n",
    " 'ibm1140': 'cp1140',\n",
    " 'iso-2022-jp': 'iso2022_jp',\n",
    " 'iso-2022-jp-1': 'iso2022_jp_1',\n",
    " 'iso-2022-jp-2': 'iso2022_jp_2',\n",
    " 'iso-2022-jp-2004': 'iso2022_jp_2004',\n",
    " 'iso-2022-jp-3': 'iso2022_jp_3',\n",
    " 'iso-2022-jp-ext': 'iso2022_jp_ext',\n",
    " 'iso-2022-kr': 'iso2022_kr',\n",
    " 'iso-8859-1': 'latin_1',\n",
    " 'iso-8859-10': 'iso8859_10',\n",
    " 'iso-8859-13': 'iso8859_13',\n",
    " 'iso-8859-14': 'iso8859_14',\n",
    " 'iso-8859-15': 'iso8859_15',\n",
    " 'iso-8859-2': 'iso8859_2',\n",
    " 'iso-8859-3': 'iso8859_3',\n",
    " 'iso-8859-4': 'iso8859_4',\n",
    " 'iso-8859-5': 'iso8859_5',\n",
    " 'iso-8859-6': 'iso8859_6',\n",
    " 'iso-8859-7': 'iso8859_7',\n",
    " 'iso-8859-8': 'iso8859_8',\n",
    " 'iso-8859-9': 'iso8859_9',\n",
    " 'iso-ir-58': 'gb2312',\n",
    " 'iso2022jp': 'iso2022_jp',\n",
    " 'iso2022jp-1': 'iso2022_jp_1',\n",
    " 'iso2022jp-2': 'iso2022_jp_2',\n",
    " 'iso2022jp-2004': 'iso2022_jp_2004',\n",
    " 'iso2022jp-3': 'iso2022_jp_3',\n",
    " 'iso2022jp-ext': 'iso2022_jp_ext',\n",
    " 'iso2022kr': 'iso2022_kr',\n",
    " 'iso8859-1': 'latin_1',\n",
    " 'jisx0213': 'euc_jis_2004',\n",
    " 'korean': 'euc_kr',\n",
    " 'ks_c-5601': 'euc_kr',\n",
    " 'ks_c-5601-1987': 'euc_kr',\n",
    " 'ks_x-1001': 'euc_kr',\n",
    " 'ksc5601': 'euc_kr',\n",
    " 'ksx1001': 'euc_kr',\n",
    " 'latin': 'latin_1',\n",
    " 'latin1': 'latin_1',\n",
    " 'latin2': 'iso8859_2',\n",
    " 'latin3': 'iso8859_3',\n",
    " 'latin4': 'iso8859_4',\n",
    " 'latin5': 'iso8859_9',\n",
    " 'latin6': 'iso8859_10',\n",
    " 'latin8': 'iso8859_14',\n",
    " 'maccentraleurope': 'mac_latin2',\n",
    " 'maccyrillic': 'mac_cyrillic',\n",
    " 'macgreek': 'mac_greek',\n",
    " 'maciceland': 'mac_iceland',\n",
    " 'maclatin2': 'mac_latin2',\n",
    " 'macroman': 'mac_roman',\n",
    " 'macturkish': 'mac_turkish',\n",
    " 'ms-kanji': 'cp932',\n",
    " 'ms1361': 'johab',\n",
    " 'ms932': 'cp932',\n",
    " 'ms936': 'gbk',\n",
    " 'ms949': 'cp949',\n",
    " 'ms950': 'cp950',\n",
    " 'mskanji': 'cp932',\n",
    " 'pt154': 'ptcp154',\n",
    " 's_jis': 'shift_jis',\n",
    " 's_jisx0213': 'shift_jisx0213',\n",
    " 'shiftjis': 'shift_jis',\n",
    " 'shiftjis2004': 'shift_jis_2004',\n",
    " 'shiftjisx0213': 'shift_jisx0213',\n",
    " 'sjis': 'shift_jis',\n",
    " 'sjis2004': 'shift_jis_2004',\n",
    " 'sjis_2004': 'shift_jis_2004',\n",
    " 'sjisx0213': 'shift_jisx0213',\n",
    " 'u-jis': 'euc_jp',\n",
    " 'uhc': 'cp949',\n",
    " 'ujis': 'euc_jp',\n",
    " 'us-ascii': 'ascii',\n",
    " 'utf16': 'utf_16',\n",
    " 'utf8': 'utf_8',\n",
    " 'windows-1250': 'cp1250',\n",
    " 'windows-1251': 'cp1251',\n",
    " 'windows-1252': 'cp1252',\n",
    " 'windows-1253': 'cp1253',\n",
    " 'windows-1254': 'cp1254',\n",
    " 'windows-1255': 'cp1255',\n",
    " 'windows-1257': 'cp1257',\n",
    " 'windows-1258': 'cp1258',\n",
    " 'windows1256': 'cp1256',\n",
    "\n",
    "}\n",
    "\n",
    "def delete():\n",
    "    a=CrawlingData.objects.all()\n",
    "    a.delete()\n",
    "\n",
    "def parse():\n",
    "    ## 설정\n",
    "    data={\n",
    "               0 : { },#instiz\n",
    "               1  : { },#clien\n",
    "               2 :  { },#fmkorea\n",
    "               3 : { },#ou\n",
    "               4 : { },#pan\n",
    "               5 : { }, #slr\n",
    "               6 : { }, #mlb\n",
    "               7 : { },#inben\n",
    "               8 : { },#ruri\n",
    "               9 : { },#utde\n",
    "              10 : { },#bobe\n",
    "               11 : { },#ygosu\n",
    "               12 : { },#drip\n",
    "               13 : { },#theqoo\n",
    "               14 : { },#dogge\n",
    "               15 : { }, #namsung\n",
    "               16 : { }, #flash1\n",
    "               17 : { }, #flash2\n",
    "               18 : { }, #dream1\n",
    "               19 : { }, #dream2\n",
    "               20 : { }, #bobe2\n",
    "               21 : { },#fomos1\n",
    "               22 : { },#fomos2\n",
    "               23 : { },#ilbe\n",
    "    }\n",
    "    #instiz\n",
    "    req = requests.get('http://www.instiz.net/bbs/list.php?id=pt&srd=1&srt=3&k=&stype=&stype2=&stype3=').text\n",
    "    soup_instiz = BeautifulSoup(req, 'html.parser')\n",
    "    #clien\n",
    "    req = requests.get('https://www.clien.net/service/group/board_all?od=T33').text\n",
    "    soup_clien = BeautifulSoup(req, 'html.parser')\n",
    "    #fmkorea\n",
    "    req = requests.get('http://www.fmkorea.com/index.php?mid=best&listStyle=list&page=1').text\n",
    "    soup_fmkorea = BeautifulSoup(req, 'html.parser')\n",
    "    #ou\n",
    "    req = requests.get('http://www.todayhumor.co.kr/board/list.php?table=bestofbest').text\n",
    "    soup_ou = BeautifulSoup(req, 'html.parser')\n",
    "    #pan\n",
    "    req = requests.get('http://pann.nate.com/talk/ranking').text\n",
    "    soup_pan = BeautifulSoup(req, 'html.parser')\n",
    "    #slr\n",
    "    req = requests.get('http://www.slrclub.com/bbs/zboard.php?id=best_article&category=1&setsearch=category').text\n",
    "    soup_slr = BeautifulSoup(req, 'html.parser')\n",
    "    #mlb\n",
    "    req = requests.get('http://mlbpark.donga.com/mp/best.php?b=bullpen&m=view').text\n",
    "    soup_mlb = BeautifulSoup(req, 'html.parser')\n",
    "    #inben\n",
    "    req = requests.get('http://www.inven.co.kr/board/powerbbs.php?come_idx=2097&query=list&my=chu&category=%EC%9C%A0%EB%A8%B8&sort=PID&name=&subject=&content=&keyword=&orderby=&iskin=webzine').text\n",
    "    soup_inben = BeautifulSoup(req, 'html.parser')\n",
    "    #ruri\n",
    "    req = requests.get('http://bbs.ruliweb.com/best/selection').text\n",
    "    soup_ruri = BeautifulSoup(req, 'html.parser')\n",
    "    #utde\n",
    "    req = requests.get('http://web.humoruniv.com/board/humor/list.html?table=pds&st=day').text.encode(encoding_map['iso-8859-1'])\n",
    "    soup_utde = BeautifulSoup(req, 'html.parser')\n",
    "    #bobe\n",
    "    req = requests.get('http://www.bobaedream.co.kr/list?code=best').text.encode(encoding_map['iso-8859-1'])\n",
    "    soup_bobe = BeautifulSoup(req, 'html.parser')\n",
    "    #ygosu\n",
    "    req = requests.get('http://www.ygosu.com/community/real_article').text\n",
    "    soup_ygosu = BeautifulSoup(req, 'html.parser')\n",
    "    #drip\n",
    "    req = requests.get('http://www.dogdrip.net/index.php?mid=dogdrip&page=1&sort_index=voted_count&order_type=desc').text\n",
    "    soup_drip = BeautifulSoup(req, 'html.parser')\n",
    "    #theqoo\n",
    "    req = requests.get('http://theqoo.net/tbest?filter_mode=normal').text\n",
    "    soup_theqoo = BeautifulSoup(req, 'html.parser')\n",
    "    #dogge\n",
    "    req = requests.get('http://dkbnews.donga.com/Board?p=1&tcode=bbs_dkbnews&s=date&key=&query=').text\n",
    "    soup_dogge = BeautifulSoup(req, 'html.parser')\n",
    "    #namsung\n",
    "    req1= requests.get('http://nsbu.co.kr/bbs/board.php?bo_table=ggolit').text\n",
    "    soup_namsung1 = BeautifulSoup(req1, 'html.parser')\n",
    "    req2 = requests.get('http://nsbu.co.kr/bbs/board.php?bo_table=celeb').text\n",
    "    soup_namsung2 = BeautifulSoup(req2, 'html.parser')\n",
    "    #flash1\n",
    "    req1= requests.get('http://flash24.dreamx.com/g4/bbs/board.php?bo_table=star&page=2&page=1').text.encode(encoding_map['iso-8859-1'])\n",
    "    soup_flash1 = BeautifulSoup(req1, 'html.parser')\n",
    "    #flash2\n",
    "    req2 = requests.get('http://flash24.dreamx.com/g4/bbs/board.php?bo_table=photo').text.encode(encoding_map['iso-8859-1'])\n",
    "    soup_flash2 = BeautifulSoup(req2, 'html.parser')\n",
    "    #dream1\n",
    "    req1= requests.get('http://newsbbs.dreamx.com/list.do?bid=cnt_star&is_image=Y').text\n",
    "    soup_dream1 = BeautifulSoup(req1, 'html.parser')\n",
    "    #dream2\n",
    "    req2 = requests.get('http://newsbbs.dreamx.com/list.do?bid=cnt_humor&is_image=Y').text\n",
    "    soup_dream2 = BeautifulSoup(req2, 'html.parser')\n",
    "    #bobe2\n",
    "    req1= requests.get('http://www.bobaedream.co.kr/list?code=girl&s_cate=&maker_no=&model_no=&or_gu=10&or_se=desc&s_selday=&pagescale=30&info3=&noticeShow=&s_select=Subject&s_key=&level_no=&vdate=&type=list&page=1')\n",
    "    req1 =req1.text.encode(encoding_map['iso-8859-1'])\n",
    "    soup_bobe2 = BeautifulSoup(req1, 'html.parser')\n",
    "    #fomos1\n",
    "    req1= requests.get('http://www.fomos.kr/talk/article_list?bbs_id=5').text\n",
    "    soup_fomos1 = BeautifulSoup(req1, 'html.parser')\n",
    "    req2 = requests.get('http://www.fomos.kr/talk/article_list?bbs_id=6').text\n",
    "    soup_fomos2 = BeautifulSoup(req2, 'html.parser')\n",
    "    #fomos2\n",
    "    req1= requests.get('http://www.fomos.kr/talk/article_list?bbs_id=3').text\n",
    "    soup_fomos3 = BeautifulSoup(req1, 'html.parser')\n",
    "    req2 = requests.get('http://www.fomos.kr/talk/article_list?bbs_id=4').text\n",
    "    soup_fomos4 = BeautifulSoup(req2, 'html.parser')\n",
    "    #ilbe\n",
    "    req1= requests.get('http://www.ilbe.com/ilbe').text\n",
    "    soup_ilbe = BeautifulSoup(req1, 'html.parser')\n",
    "\n",
    "    \n",
    "    ## json에 저장\n",
    "    #instiz\n",
    "    for title in soup_instiz.select('#subject a'): \n",
    "                    a = title.get('href')\n",
    "                    b=a.replace(\"..\" , \"instiz.net\")\n",
    "                    data[0][title.text] = b\n",
    "    #clien\n",
    "    n=0\n",
    "    for title in soup_clien.select('.list-title .list-subject'): \n",
    "        if n == 0:\n",
    "            n+=1\n",
    "            continue\n",
    "        else:\n",
    "            a = title.get('href')\n",
    "            if not a==None:\n",
    "                    a='clien.net' + a\n",
    "                    str=\" \".join(title.text.strip().split())\n",
    "                    data[1][str] = a\n",
    "    #fmkorea\n",
    "    for title in soup_fmkorea.select('.hx'): \n",
    "                    a = title.get('href')\n",
    "                    data[2][title.text.strip()] = a\n",
    "    #ou\n",
    "    for title in soup_ou.select('.subject a'): \n",
    "                    a = title.get('href')\n",
    "                    a='todayhumor.co.kr' + a\n",
    "                    data[3][title.text] = a\n",
    "    #pan\n",
    "    for title in soup_pan.select('dt a'): \n",
    "                    a = title.get('href')\n",
    "                    data[4][title.text] = a\n",
    "    #slr\n",
    "    for title in soup_slr.select('.sbj a'): \n",
    "                    a = title.get('href')\n",
    "                    a='slrclub.com'+a\n",
    "                    data[5][title.text] = a\n",
    "    #mlb\n",
    "    for title in soup_mlb.select('.t_left a'): \n",
    "                    a = title.get('href')\n",
    "                    data[6][title.text] = a\n",
    "    #inben\n",
    "    for title in soup_inben.select('a.sj_ln'): \n",
    "                    a = title.get('href')\n",
    "                    data[7][title.text] = a\n",
    "    #ruri\n",
    "    for title in soup_ruri.select('.subject a'): \n",
    "                    a = title.get('href')\n",
    "                    data[8][title.text] = a\n",
    "     #utde\n",
    "    for title in soup_utde.select('a.brn3, a.brn2, a.brn1'): \n",
    "                    a = title.get('href')\n",
    "                    a='web.humoruniv.com/board/humor/'+a\n",
    "                    str=\" \".join(title.text.strip().split())\n",
    "                    data[9][str] = a\n",
    "    #bobe\n",
    "    for title in soup_bobe.select('a.bsubject'): \n",
    "                    a = title.get('href')\n",
    "                    a='bobaedream.co.kr'+a\n",
    "                    data[10][title.text] = a\n",
    "    #ygosu\n",
    "    for title in soup_ygosu.select('.tit a'): \n",
    "                    a = title.get('href')\n",
    "                    data[11][title.text] = a\n",
    "     #drip\n",
    "    n=0\n",
    "    for title in soup_drip.select('td.title a'): \n",
    "                if n == 0:\n",
    "                      n+=1\n",
    "                      continue\n",
    "                else:\n",
    "                     a = title.get('href')\n",
    "                     data[12][title.text.strip()] = a\n",
    "    #theqoo\n",
    "    j=0 \n",
    "    n=1\n",
    "    x=1\n",
    "    m=2\n",
    "    for title in soup_theqoo.select('td.title a'): \n",
    "            if j < 8 :\n",
    "                     j+=1\n",
    "                     continue\n",
    "            else:\n",
    "                    if  n == m:\n",
    "                            a=title.get('href')\n",
    "                            a='theqoo.net'+a.replace('_comment','') \n",
    "                            n+=1\n",
    "                            x+=1\n",
    "                            m=2*x\n",
    "                            data[13][title.text] = a\n",
    "                            continue\n",
    "                    else:\n",
    "                            n+=1\n",
    "                            continue\n",
    "    #dogge\n",
    "    for title in soup_dogge.select('.txt a'): \n",
    "                    a = title.get('href')\n",
    "                    a ='http://dkbnews.donga.com/Board'+a\n",
    "                    data[14][title.text.strip()] = a\n",
    "    #namsung\n",
    "    n=0\n",
    "    for title in soup_namsung1.select('.list-subject a'): \n",
    "                    if n < 10:\n",
    "                        a = title.get('href')\n",
    "                        n+=1\n",
    "                        data[15][title.text.strip()]=a\n",
    "                    else:\n",
    "                          break                   \n",
    "    for title in soup_namsung2.select('.list-subject a'): \n",
    "                     if n < 19:\n",
    "                        a = title.get('href')\n",
    "                        n+=1\n",
    "                        data[15][title.text.strip()]=a\n",
    "                     else:\n",
    "                          break\n",
    "    #flash1\n",
    "    n=0\n",
    "    for title in soup_flash1.select('.subject a'): \n",
    "                    if n == 0:\n",
    "                        n+=1\n",
    "                        continue\n",
    "                    else:\n",
    "                        a = title.get('href')\n",
    "                        a = a.replace('..','flash24.dreamx.com/g4')\n",
    "                        data[16][title.text]=a\n",
    "     #flash2\n",
    "    n=0\n",
    "    for title in soup_flash2.select('.subject a'): \n",
    "                    if n == 0:\n",
    "                        n+=1\n",
    "                        continue\n",
    "                    else:\n",
    "                        a = title.get('href')\n",
    "                        a = a.replace('..','flash24.dreamx.com/g4')\n",
    "                        data[17][title.text]=a\n",
    "    #dream1\n",
    "    n=1\n",
    "    x=1\n",
    "    m=2\n",
    "    for title in soup_dream1.select('.bbs_list_list a'): \n",
    "                        if  n == m:\n",
    "                                a=title.get('href')\n",
    "                                a='newsbbs.dreamx.com'+a\n",
    "                                n+=1\n",
    "                                x+=1\n",
    "                                m=2*x\n",
    "                                data[18][title.text.strip()]=a\n",
    "                                continue\n",
    "                        else:\n",
    "                                n+=1\n",
    "                                continue\n",
    "    #dream2\n",
    "    n=1\n",
    "    x=1\n",
    "    m=2\n",
    "    for title in soup_dream2.select('.bbs_list_list a'): \n",
    "                        if  n == m:\n",
    "                                a=title.get('href')\n",
    "                                a='newsbbs.dreamx.com'+a\n",
    "                                n+=1\n",
    "                                x+=1\n",
    "                                m=2*x\n",
    "                                data[19][title.text.strip()]=a\n",
    "                                continue\n",
    "                        else:\n",
    "                                n+=1\n",
    "                                continue\n",
    "    #bobe2\n",
    "    for title in soup_bobe2.select('.pl14 a.bsubject'): \n",
    "                    a=title.get('href')\n",
    "                    a='bobaedream.co.kr'+a\n",
    "                    data[20][title.text.strip()]=a\n",
    "    #fomos1\n",
    "    n=0\n",
    "    for title in soup_fomos1.select('.ranking a'): \n",
    "                        if n < 10:\n",
    "                                n+=1\n",
    "                                a=title.get('href')\n",
    "                                a='www.fomos.kr'+a\n",
    "                                data[21][title.text.strip()]=a\n",
    "                        else:\n",
    "                                break\n",
    "    n=0\n",
    "    for title in soup_fomos2.select('.ranking a'): \n",
    "                        if n < 10:\n",
    "                                n+=1\n",
    "                                a=title.get('href')\n",
    "                                a='www.fomos.kr'+a\n",
    "                                data[21][title.text.strip()]=a\n",
    "                        else:\n",
    "                                break\n",
    "    #fomos2\n",
    "    n=0\n",
    "    for title in soup_fomos3.select('.ranking a'): \n",
    "                        if n < 10:\n",
    "                                n+=1\n",
    "                                a=title.get('href')\n",
    "                                a='www.fomos.kr'+a\n",
    "                                data[22][title.text.strip()]=a\n",
    "                        else:\n",
    "                                break\n",
    "    n=0\n",
    "    for title in soup_fomos4.select('.ranking a'): \n",
    "                        if n < 10:\n",
    "                                n+=1\n",
    "                                a=title.get('href')\n",
    "                                a='www.fomos.kr'+a\n",
    "                                data[22][title.text.strip()]=a\n",
    "                        else:\n",
    "                                break\n",
    "     #ilbe\n",
    "    n=0\n",
    "    for title in soup_ilbe.select('.title a'): \n",
    "                    if n == 0:\n",
    "                            n+=1\n",
    "                            continue\n",
    "                    else:\n",
    "                            a=title.get('href')\n",
    "                            data[23][title.text.strip()]=a\n",
    "\n",
    "\n",
    "     #한꺼번에 DB 에  insert 하기 위한 함수\n",
    "    \n",
    "    def allsave(x):\n",
    "            crawling = CrawlingData()\n",
    "            list = [\n",
    "                       [crawling.instiz, crawling.link_instiz], [crawling.clien, crawling.link_clien], [crawling.fmkorea, crawling.link_fmkorea],\n",
    "                       [crawling.ou, crawling.link_ou] ,[crawling.pan, crawling.link_pan],[crawling.slr, crawling.link_slr],[crawling.mlb, crawling.link_mlb],\n",
    "                       [crawling.inben, crawling.link_inben],[crawling.ruri, crawling.link_ruri],[crawling.utde, crawling.link_utde],[crawling.bobe, crawling.link_bobe],\n",
    "                       [crawling.ygosu, crawling.link_ygosu],[crawling.drip, crawling.link_drip],[crawling.theqoo, crawling.link_theqoo],\n",
    "                       [crawling.dogge, crawling.link_dogge],[crawling.namsung, crawling.link_namsung],[crawling.flash1, crawling.link_flash1],\n",
    "                       [crawling.flash2, crawling.link_flash2],[crawling.dream1, crawling.link_dream1],[crawling.dream2, crawling.link_dream2],\n",
    "                       [crawling.bobe2, crawling.link_bobe2],[crawling.fomos1, crawling.link_fomos1], [crawling.fomos2, crawling.link_fomos2],\n",
    "                       [crawling.ilbe, crawling.link_ilbe]\n",
    "                   ]\n",
    "            for  i in range(len(data)):\n",
    "                    n=0\n",
    "                    for t,l in data[i].items():\n",
    "                        if n == x:\n",
    "                            list[i][0],list[i][1]= t,l\n",
    "                            print(list[i][0],list[i][1])\n",
    "                            break\n",
    "                        else:\n",
    "                            n+=1\n",
    "                            continue\n",
    "            \n",
    "            CrawlingData(instiz=list[0][0],link_instiz=list[0][1], clien=list[1][0],link_clien=list[1][1], fmkorea=list[2][0],link_fmkorea=list[2][1],\n",
    "                                  ou=list[3][0],link_ou=list[3][1], pan=list[4][0],link_pan=list[4][1], slr=list[5][0],link_slr=list[5][1], mlb=list[6][0],link_mlb=list[6][1],\n",
    "                                  inben=list[7][0],link_inben=list[7][1], ruri=list[8][0],link_ruri=list[8][1], utde=list[9][0],link_utde=list[9][1],\n",
    "                                  bobe=list[10][0],link_bobe=list[10][1], ygosu=list[11][0],link_ygosu=list[11][1], drip=list[12][0],link_drip=list[12][1],\n",
    "                                  theqoo=list[13][0],link_theqoo=list[13][1], dogge=list[14][0],link_dogge=list[14][1], namsung=list[15][0],link_namsung=list[15][1],\n",
    "                                  flash1=list[16][0],link_flash1=list[16][1], flash2=list[17][0],link_flash2=list[17][1], dream1=list[18][0],link_dream1=list[18][1],\n",
    "                                  dream2=list[19][0],link_dream2=list[19][1], bobe2=list[20][0],link_bobe2=list[20][1], fomos1=list[21][0],link_fomos1=list[21][1],\n",
    "                                  fomos2=list[22][0],link_fomos2=list[22][1], ilbe=list[23][0],link_ilbe=list[23][1],\n",
    "                                    ).save() \n",
    "            \n",
    "       ##DB에 저장\n",
    "    for x in range(len(data[0])):\n",
    "                    allsave(x)\n",
    "                    print('-----------')\n",
    "                    \n",
    "    \n",
    "while True:\n",
    "    print('start parsing')\n",
    "    delete()\n",
    "    parse()\n",
    "    print('parsing ends')\n",
    "    print('sleep in 40s')\n",
    "    time.sleep(60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "req2 = requests.get('').text\n",
    "soup_flash2 = BeautifulSoup(req2, 'html.parser')\n",
    "\n",
    "    #ruri\n",
    "for title in soup_flash2.select(''): \n",
    "                    a = title.get('href')\n",
    "                    print(title.text)\n",
    "                    print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
